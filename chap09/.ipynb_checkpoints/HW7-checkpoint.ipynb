{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff85efb7-5394-4281-8628-2fa7691c7c05",
   "metadata": {},
   "source": [
    "## 10. 다음 계층에서 2X2 최대 풀링을 수행하고 결과를 적어보자. (5점)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fedaf4b3-bb95-46a8-8be0-21e9f2e2e76d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 99 190]\n",
      " [ 15  45]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "arr = np.array([[28,15,27,190],[1,99,70,38],[15,12,45,2], [10,8,7,6]])\n",
    "\n",
    "arr\n",
    "\n",
    "arr[0:2, 0:2], arr[0:2, 2:4], arr[2:4, 0:2], arr[2:4, 2:4]\n",
    "\n",
    "def max_poolling(arr, polling_size):\n",
    "    height, width = arr.shape\n",
    "    p_height, p_width = polling_size\n",
    "    res = []\n",
    "    for i in range(0,height, p_height):\n",
    "        for j in range(0,width, p_width):\n",
    "            m = np.max(arr[i:i+p_height, j:j+p_width])\n",
    "            res.append([m])\n",
    "    return np.array(res)\n",
    "\n",
    "res = max_poolling(arr, (2,2)).reshape(2,2)\n",
    "\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8706ed-3edb-4830-98b9-e426bbfcc968",
   "metadata": {},
   "source": [
    "### 11. 우리는 7장에서 패션 아이템을 분류하는 MLP 신경망을 작성한 적이 있다.우리는 케라스에서 기본적으로 제공하는 패션 MNIST 데이터 세트를 사용한다. 10개의 범주의 약 7만개의 패션 관련 이미지가 제공된다. 해상도는 28X28이다. 동일한 작업을 컨벌루션 신경망을 이용하여 시도해보자. 성능이 얼마나 증가되는가? (10점)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "46260369-6a92-4739-a961-5ee8e745aa12",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 13ms/step - accuracy: 0.7410 - loss: 0.7037\n",
      "Epoch 2/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 13ms/step - accuracy: 0.8785 - loss: 0.3338\n",
      "Epoch 3/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 13ms/step - accuracy: 0.8989 - loss: 0.2770\n",
      "Epoch 4/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 13ms/step - accuracy: 0.9112 - loss: 0.2421\n",
      "Epoch 5/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 13ms/step - accuracy: 0.9205 - loss: 0.2159\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8949 - loss: 0.3002\n",
      "Epoch 1/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.7795 - loss: 0.6347\n",
      "Epoch 2/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.8599 - loss: 0.3909\n",
      "Epoch 3/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.8742 - loss: 0.3443\n",
      "Epoch 4/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.8856 - loss: 0.3166\n",
      "Epoch 5/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.8950 - loss: 0.2884\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8766 - loss: 0.3516\n",
      "cnn 정확도: 0.8960000276565552\n",
      "dnn 정확도:  0.8761000037193298\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras import datasets\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#cnn모델만들기\n",
    "inputs = Input(shape=(28,28,1))\n",
    "x = Conv2D(32, (3, 3), activation='relu')(inputs)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu')(x)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu')(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "outputs = Dense(10, activation='softmax')(x)\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "#전처리\n",
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "#결과\n",
    "model.fit(train_images, train_labels, epochs=5)\n",
    "test_loss, cnn_test_acc = model.evaluate(test_images, test_labels)\n",
    "\n",
    "#mlp\n",
    "inputs = Input(shape = (28,28))\n",
    "flatten = Flatten()(inputs)\n",
    "hidden1 = Dense(128, activation = 'relu')(flatten)\n",
    "outputs = Dense(10, activation = 'softmax')(hidden1)\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_images, train_labels, epochs=5)\n",
    "test_loss, dnn_test_acc = model.evaluate(test_images, test_labels)\n",
    "print('cnn 정확도:', cnn_test_acc)\n",
    "print(\"dnn 정확도:\", dnn_test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3cf817-3da8-4808-b331-c59d097476c4",
   "metadata": {},
   "source": [
    "결과 : cnn정확도가 0.01정도 성능이 더 좋다 (기존 fashion.py랑 비교를 해야되는건지 숙제로 작성한 mlp랑 비교해야 하는건지 몰라서 첨부해주신 fashion.py랑 비교했습니다)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d018a9-04b1-476b-8f6a-436280502082",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
